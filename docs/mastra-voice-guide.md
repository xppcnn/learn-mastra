# Mastra Voiceï¼ˆè¯­éŸ³ï¼‰ä¸“é¢˜æŒ‡å—

## 1. ä»€ä¹ˆæ˜¯ Voiceï¼Ÿ

Voiceï¼ˆè¯­éŸ³ï¼‰ç³»ç»Ÿæä¾›ç»Ÿä¸€çš„è¯­éŸ³äº¤äº’æ¥å£ï¼ŒåŒ…æ‹¬æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰ã€è¯­éŸ³è½¬æ–‡æœ¬ï¼ˆSTTï¼‰å’Œå®æ—¶è¯­éŸ³åˆ°è¯­éŸ³ï¼ˆSTSï¼‰åŠŸèƒ½ã€‚

### æ ¸å¿ƒèƒ½åŠ›
- ğŸ—£ï¸ **TTSï¼ˆText-to-Speechï¼‰** - å°†æ–‡æœ¬è½¬æ¢ä¸ºè‡ªç„¶è¯­éŸ³
- ğŸ‘‚ **STTï¼ˆSpeech-to-Textï¼‰** - å°†è¯­éŸ³è½¬æ¢ä¸ºæ–‡æœ¬
- ğŸ™ï¸ **STSï¼ˆSpeech-to-Speechï¼‰** - å®æ—¶åŒå‘è¯­éŸ³äº¤äº’
- ğŸ”Š **å¤šæä¾›å•†æ”¯æŒ** - ç»Ÿä¸€ API è®¿é—®å¤šä¸ªè¯­éŸ³æœåŠ¡

---

## 2. æ”¯æŒçš„æä¾›å•†

### 2.1 TTS æä¾›å•†

| æä¾›å•† | åŒ…å | ç‰¹ç‚¹ |
|--------|------|------|
| OpenAI | `@mastra/voice-openai` | é«˜è´¨é‡ã€è‡ªç„¶è¯­è°ƒ |
| ElevenLabs | `@mastra/voice-elevenlabs` | è¶…é€¼çœŸè¯­éŸ³ |
| PlayAI | `@mastra/voice-playai` | å¤šç§é£æ ¼ |
| Google | `@mastra/voice-google` | å¤šè¯­è¨€æ”¯æŒ |
| Azure | `@mastra/voice-azure` | ä¼ä¸šçº§æœåŠ¡ |
| Deepgram | `@mastra/voice-deepgram` | AI é©±åŠ¨ |
| Cloudflare | `@mastra/voice-cloudflare` | è¾¹ç¼˜ä¼˜åŒ– |
| Speechify | `@mastra/voice-speechify` | å¯è¯»æ€§ä¼˜åŒ– |
| Murf | `@mastra/voice-murf` | å·¥ä½œå®¤çº§å“è´¨ |
| Sarvam | `@mastra/voice-sarvam` | å°åº¦è¯­è¨€ä¸“ç²¾ |

### 2.2 STT æä¾›å•†

| æä¾›å•† | åŒ…å |
|--------|------|
| OpenAI | `@mastra/voice-openai` |
| Google | `@mastra/voice-google` |
| Azure | `@mastra/voice-azure` |
| Deepgram | `@mastra/voice-deepgram` |
| ElevenLabs | `@mastra/voice-elevenlabs` |
| Sarvam | `@mastra/voice-sarvam` |

### 2.3 STS æä¾›å•†ï¼ˆå®æ—¶ï¼‰

| æä¾›å•† | åŒ…å |
|--------|------|
| OpenAI Realtime | `@mastra/voice-openai-realtime` |
| Google Gemini Live | `@mastra/voice-google-gemini-live` |

---

## 3. Text-to-Speechï¼ˆTTSï¼‰

### 3.1 åŸºæœ¬ä½¿ç”¨

```typescript
import { Agent } from "@mastra/core/agent";
import { OpenAIVoice } from "@mastra/voice-openai";
import { openai } from "@ai-sdk/openai";
import { playAudio } from "@mastra/node-audio";

const voiceAgent = new Agent({
  name: "Voice Agent",
  instructions: "ä½ æ˜¯ä¸€ä¸ªè¯­éŸ³åŠ©æ‰‹ã€‚",
  model: openai("gpt-4o"),
  voice: new OpenAIVoice(),
});

// ç”Ÿæˆå“åº”
const { text } = await voiceAgent.generate("ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ");

// è½¬æ¢ä¸ºè¯­éŸ³
const audioStream = await voiceAgent.voice.speak(text, {
  speaker: "alloy", // å¯é€‰ï¼šæŒ‡å®šè¯´è¯äºº
  responseFormat: "wav", // å¯é€‰ï¼šæŒ‡å®šæ ¼å¼
});

// æ’­æ”¾éŸ³é¢‘
playAudio(audioStream);
```

### 3.2 ä¿å­˜éŸ³é¢‘åˆ°æ–‡ä»¶

```typescript
import { createWriteStream } from "fs";
import path from "path";

const audio = await agent.voice.speak("ä½ å¥½ï¼Œä¸–ç•Œï¼");
const filePath = path.join(process.cwd(), "output.mp3");
const writer = createWriteStream(filePath);

audio.pipe(writer);

await new Promise((resolve, reject) => {
  writer.on("finish", () => resolve());
  writer.on("error", reject);
});
```

### 3.3 å„æä¾›å•†é…ç½®

```typescript
// OpenAI
const voice = new OpenAIVoice({
  speechModel: {
    name: "tts-1-hd",
    apiKey: process.env.OPENAI_API_KEY,
  },
  speaker: "alloy", // alloy, echo, fable, onyx, nova, shimmer
});

// ElevenLabs
import { ElevenLabsVoice } from "@mastra/voice-elevenlabs";
const voice = new ElevenLabsVoice({
  speechModel: {
    voiceId: "your-voice-id",
    model: "eleven_multilingual_v2",
    apiKey: process.env.ELEVENLABS_API_KEY,
  },
});

// Google
import { GoogleVoice } from "@mastra/voice-google";
const voice = new GoogleVoice({
  speechModel: {
    name: "en-US-Studio-O",
    apiKey: process.env.GOOGLE_API_KEY,
    languageCode: "en-US",
    gender: "FEMALE",
  },
});

// Azure
import { AzureVoice } from "@mastra/voice-azure";
const voice = new AzureVoice({
  speechModel: {
    name: "en-US-JennyNeural",
    apiKey: process.env.AZURE_SPEECH_KEY,
    region: process.env.AZURE_SPEECH_REGION,
    style: "cheerful",
  },
});
```

---

## 4. Speech-to-Textï¼ˆSTTï¼‰

### 4.1 åŸºæœ¬ä½¿ç”¨

```typescript
import { Agent } from "@mastra/core/agent";
import { OpenAIVoice } from "@mastra/voice-openai";
import { createReadStream } from "fs";

const voiceAgent = new Agent({
  name: "Voice Agent",
  instructions: "ä½ æ˜¯ä¸€ä¸ªè¯­éŸ³åŠ©æ‰‹ã€‚",
  model: openai("gpt-4o"),
  voice: new OpenAIVoice(),
});

// ä»æ–‡ä»¶è¯»å–éŸ³é¢‘
const audioStream = createReadStream("./audio.mp3");

// è½¬æ¢ä¸ºæ–‡æœ¬
const transcript = await voiceAgent.voice.listen(audioStream, {
  filetype: "mp3", // å¯é€‰ï¼šæŒ‡å®šæ–‡ä»¶ç±»å‹
});

console.log(`ç”¨æˆ·è¯´: ${transcript}`);

// ç”Ÿæˆå“åº”
const { text } = await voiceAgent.generate(transcript);
```

### 4.2 é…ç½® STT æ¨¡å‹

```typescript
// OpenAI Whisper
const voice = new OpenAIVoice({
  listeningModel: {
    name: "whisper-1",
    apiKey: process.env.OPENAI_API_KEY,
    language: "zh", // æŒ‡å®šè¯­è¨€
  },
});

// Deepgram
import { DeepgramVoice } from "@mastra/voice-deepgram";
const voice = new DeepgramVoice({
  listeningModel: {
    name: "nova-2",
    apiKey: process.env.DEEPGRAM_API_KEY,
    format: "flac",
  },
});

// Google
const voice = new GoogleVoice({
  listeningModel: {
    name: "en-US",
    sampleRateHertz: 16000,
  },
});
```

---

## 5. Speech-to-Speechï¼ˆSTSï¼‰

### 5.1 æ¦‚å¿µ

STS é€šè¿‡æŒç»­çš„åŒå‘éŸ³é¢‘é€šä¿¡æä¾›å®æ—¶è¯­éŸ³äº¤äº’ï¼Œä¸åˆ†ç¦»çš„ TTS å’Œ STT æ“ä½œä¸åŒï¼ŒSTS ç»´æŠ¤ä¸€ä¸ªæŒç»­å¤„ç†åŒå‘è¯­éŸ³çš„å¼€æ”¾è¿æ¥ã€‚

### 5.2 OpenAI Realtime

```typescript
import { Agent } from "@mastra/core/agent";
import { OpenAIRealtimeVoice } from "@mastra/voice-openai-realtime";
import { playAudio, getMicrophoneStream } from "@mastra/node-audio";

const agent = new Agent({
  name: "Realtime Agent",
  instructions: "ä½ æ˜¯ä¸€ä¸ªå…·æœ‰å®æ—¶è¯­éŸ³åŠŸèƒ½çš„åŠ©æ‰‹ã€‚",
  model: openai("gpt-4o"),
  voice: new OpenAIRealtimeVoice({
    model: "gpt-4o-mini-realtime",
    speaker: "alloy",
  }),
});

// è¿æ¥åˆ°è¯­éŸ³æœåŠ¡
await agent.voice.connect();

// ç›‘å¬éŸ³é¢‘å“åº”
agent.voice.on("speaker", ({ audio }) => {
  playAudio(audio);
});

// ç›‘å¬æ–‡æœ¬è½¬å½•
agent.voice.on("writing", ({ text, role }) => {
  console.log(`${role}: ${text}`);
});

// å¼€å§‹å¯¹è¯
await agent.voice.speak("æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„ï¼Ÿ");

// å‘é€éº¦å…‹é£éŸ³é¢‘
const micStream = getMicrophoneStream();
await agent.voice.send(micStream);

// å®Œæˆåå…³é—­è¿æ¥
// agent.voice.close();
```

### 5.3 Google Gemini Live

```typescript
import { GeminiLiveVoice } from "@mastra/voice-google-gemini-live";

const agent = new Agent({
  name: "Gemini Live Agent",
  instructions: "ä½ æ˜¯ä¸€ä¸ªå…·æœ‰å®æ—¶è¯­éŸ³åŠŸèƒ½çš„åŠ©æ‰‹ã€‚",
  model: openai("gpt-4o"),
  voice: new GeminiLiveVoice({
    apiKey: process.env.GOOGLE_API_KEY,
    model: "gemini-2.0-flash-exp",
    speaker: "Puck",
    debug: true,
  }),
});

// è¿æ¥ï¼ˆå¿…é¡»åœ¨ä½¿ç”¨å‰è°ƒç”¨ï¼‰
await agent.voice.connect();

// ç›‘å¬äº‹ä»¶
agent.voice.on("speaker", ({ audio }) => {
  playAudio(audio);
});

agent.voice.on("writing", ({ role, text }) => {
  console.log(`${role}: ${text}`);
});

// å¼€å§‹å¯¹è¯
await agent.voice.speak("æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„ï¼Ÿ");

// å‘é€éº¦å…‹é£éŸ³é¢‘
const micStream = getMicrophoneStream();
await agent.voice.send(micStream);
```

### 5.4 äº‹ä»¶ç³»ç»Ÿ

```typescript
// ç›‘å¬è¯­éŸ³è¾“å‡º
agent.voice.on("speaker", ({ audio }) => {
  // audio æ˜¯ ReadableStream æˆ– Int16Array
});

// ç›‘å¬æ–‡æœ¬è½¬å½•
agent.voice.on("writing", ({ text, role }) => {
  console.log(`${role} è¯´: ${text}`);
});

// ç›‘å¬é”™è¯¯
agent.voice.on("error", (error) => {
  console.error("è¯­éŸ³é”™è¯¯:", error);
});
```

---

## 6. CompositeVoiceï¼ˆç»„åˆè¯­éŸ³ï¼‰

### 6.1 ä½¿ç”¨ä¸åŒæä¾›å•†

```typescript
import { CompositeVoice } from "@mastra/core/voice";
import { OpenAIVoice } from "@mastra/voice-openai";
import { PlayAIVoice } from "@mastra/voice-playai";

// ä½¿ç”¨ OpenAI è¿›è¡Œ STTï¼ŒPlayAI è¿›è¡Œ TTS
const voice = new CompositeVoice({
  input: new OpenAIVoice(),  // STT
  output: new PlayAIVoice(), // TTS
});

const agent = new Agent({
  name: "Composite Voice Agent",
  instructions: "ä½ æ˜¯ä¸€ä¸ªè¯­éŸ³åŠ©æ‰‹ã€‚",
  model: openai("gpt-4o"),
  voice,
});
```

### 6.2 ä½¿ç”¨ AI SDK æ¨¡å‹

```typescript
import { CompositeVoice } from "@mastra/core/voice";
import { openai } from "@ai-sdk/openai";
import { elevenlabs } from "@ai-sdk/elevenlabs";

// ç›´æ¥ä½¿ç”¨ AI SDK æ¨¡å‹
const voice = new CompositeVoice({
  input: openai.transcription("whisper-1"),       // STT
  output: elevenlabs.speech("eleven_turbo_v2"),   // TTS
});
```

### 6.3 æ··åˆä½¿ç”¨

```typescript
import { CompositeVoice } from "@mastra/core/voice";
import { PlayAIVoice } from "@mastra/voice-playai";
import { groq } from "@ai-sdk/groq";

// æ··åˆ AI SDK å’Œ Mastra æä¾›å•†
const voice = new CompositeVoice({
  input: groq.transcription("whisper-large-v3"),  // AI SDK STT
  output: new PlayAIVoice(),                       // Mastra TTS
});
```

---

## 7. å®Œæ•´ç¤ºä¾‹ï¼šè¯­éŸ³åŠ©æ‰‹

```typescript
import { Agent } from "@mastra/core/agent";
import { OpenAIVoice } from "@mastra/voice-openai";
import { openai } from "@ai-sdk/openai";
import { playAudio, getMicrophoneStream } from "@mastra/node-audio";
import { createReadStream, createWriteStream } from "fs";
import path from "path";

// åˆ›å»ºè¯­éŸ³æ™ºèƒ½ä½“
const voiceAgent = new Agent({
  name: "Voice Assistant",
  instructions: `
    ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„è¯­éŸ³åŠ©æ‰‹ã€‚
    ä¿æŒå›ç­”ç®€æ´ã€‚
    å¦‚æœç”¨æˆ·è¯´"å†è§"ï¼Œç¤¼è²Œåœ°ç»“æŸå¯¹è¯ã€‚
  `,
  model: openai("gpt-4o"),
  voice: new OpenAIVoice({
    speechModel: { name: "tts-1-hd" },
    listeningModel: { name: "whisper-1" },
    speaker: "nova",
  }),
});

// è¾…åŠ©å‡½æ•°ï¼šä¿å­˜éŸ³é¢‘
async function saveAudio(audio, filename) {
  const audioDir = path.join(process.cwd(), "audio");
  await fs.promises.mkdir(audioDir, { recursive: true });
  
  const filePath = path.join(audioDir, filename);
  const writer = createWriteStream(filePath);
  audio.pipe(writer);
  
  return new Promise((resolve, reject) => {
    writer.on("finish", resolve);
    writer.on("error", reject);
  });
}

// ä¸»æµç¨‹
async function main() {
  // 1. æ™ºèƒ½ä½“æ‰“æ‹›å‘¼
  const greeting = "ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„è¯­éŸ³åŠ©æ‰‹ã€‚æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„ï¼Ÿ";
  const greetingAudio = await voiceAgent.voice.speak(greeting);
  await saveAudio(greetingAudio, "greeting.mp3");
  playAudio(greetingAudio);

  // 2. ç”¨æˆ·è¾“å…¥ï¼ˆä»æ–‡ä»¶è¯»å–ï¼‰
  const userAudio = createReadStream("./user_input.mp3");
  const transcript = await voiceAgent.voice.listen(userAudio);
  console.log(`ç”¨æˆ·: ${transcript}`);

  // 3. ç”Ÿæˆå“åº”
  const { text } = await voiceAgent.generate(transcript);
  console.log(`åŠ©æ‰‹: ${text}`);

  // 4. è½¬æ¢ä¸ºè¯­éŸ³å¹¶æ’­æ”¾
  const responseAudio = await voiceAgent.voice.speak(text);
  await saveAudio(responseAudio, "response.mp3");
  playAudio(responseAudio);
}

main().catch(console.error);
```

---

## 8. æœ€ä½³å®è·µ

1. **é€‰æ‹©åˆé€‚çš„æä¾›å•†** - æ ¹æ®è´¨é‡ã€æˆæœ¬å’Œå»¶è¿Ÿéœ€æ±‚é€‰æ‹©
2. **é…ç½®è¯­è¨€** - ç¡®ä¿ TTS å’Œ STT ä½¿ç”¨ç›¸åŒçš„è¯­è¨€è®¾ç½®
3. **å¤„ç†é”™è¯¯** - å®ç°è¯­éŸ³æœåŠ¡çš„é”™è¯¯å¤„ç†å’Œé‡è¯•é€»è¾‘
4. **ä¼˜åŒ–å»¶è¿Ÿ** - å¯¹äºå®æ—¶åº”ç”¨ï¼Œä½¿ç”¨ STS è€Œä¸æ˜¯åˆ†ç¦»çš„ TTS/STT
5. **ç®¡ç†è¿æ¥** - ä½¿ç”¨ STS æ—¶ï¼Œç¡®ä¿æ­£ç¡®ç®¡ç† WebSocket è¿æ¥
6. **éŸ³é¢‘æ ¼å¼** - é€‰æ‹©ä¸åº”ç”¨å…¼å®¹çš„éŸ³é¢‘æ ¼å¼

---

## 9. å‚è€ƒèµ„æ–™

- [Mastra å®˜æ–¹æ–‡æ¡£ - Voice](https://mastra.ai/docs/voice/overview)
- [Mastra å®˜æ–¹æ–‡æ¡£ - TTS](https://mastra.ai/docs/voice/text-to-speech)
- [Mastra å®˜æ–¹æ–‡æ¡£ - STT](https://mastra.ai/docs/voice/speech-to-text)
- [Mastra å®˜æ–¹æ–‡æ¡£ - STS](https://mastra.ai/docs/voice/speech-to-speech)
- [Mastra GitHub ä»“åº“](https://github.com/mastra-ai/mastra)

---

*æ–‡æ¡£ç”Ÿæˆæ—¥æœŸï¼š2025å¹´12æœˆ10æ—¥*

